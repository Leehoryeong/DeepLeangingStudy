{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part8_TensorFlow",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsnlshCXHC5/+u5fMweCIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leehoryeong/DeepLeangingStudy/blob/master/Part8_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4tGJg82ei0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijk4FQG1elfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8641d11f-5bae-49f8-8200-d2c212166d62"
      },
      "source": [
        "# 상수노드 정의\n",
        "a = tf.constant(1.0,name='a')\n",
        "b = tf.constant(2.0,name='b')\n",
        "c = tf.constant([[1.0,2.0],[3.0,4.0]])\n",
        "\n",
        "print(a)\n",
        "print(a+b)\n",
        "print(c)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"a_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"add_4:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_1:0\", shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrW6brPeenJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "31c6aac7-3103-42f4-9595-dea6926e8198"
      },
      "source": [
        "  # 세션 생성, 노드간의 텐서 연산 실행\n",
        "  # 세션을 통해 노드에 값 할당\n",
        "sess = tf.Session()\n",
        "print(sess.run([a,b]))\n",
        "\n",
        "print(sess.run(c))\n",
        "print(sess.run([a+b]))\n",
        "print(sess.run(c+1.0))\n",
        "sess.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 2.0]\n",
            "[[1. 2.]\n",
            " [3. 4.]]\n",
            "[3.0]\n",
            "[[2. 3.]\n",
            " [4. 5.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXN5Uhnzfn9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "a610e221-a06f-48f5-9a99-f5a5ede421af"
      },
      "source": [
        "# 플레이스홀더 노드 - 임의의 값 입력 받는 경우\n",
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "c = a+b\n",
        "\n",
        "\n",
        "# 노드간의 연산을 위해 세션 생성\n",
        "sess = tf.Session()\n",
        "# c: 실행하고자 하는 연산 feed_dict:실제로 넣을 값 \n",
        "print(sess.run(c, feed_dict={a:1.0, b:3.0}))\n",
        "print(sess.run(c, feed_dict={a:[1.0,2.0], b:[3.0,4.0]}))\n",
        "\n",
        "d = 100 * c\n",
        "# d: 실행하고자 하는 연산 feed_dict:실제로 넣을 값 \n",
        "\n",
        "print(sess.run(d, feed_dict={a:1.0, b:3.0}))\n",
        "print(sess.run(d, feed_dict={a:[1.0,2.0], b:[3.0,4.0]}))\n",
        "\n",
        "# 세션 close\n",
        "sess.close()\n",
        "\n",
        "# 플레이스홀더 노드는 입력, 정답데이터를 넣어 주기 위해사용 "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n",
            "[4. 6.]\n",
            "400.0\n",
            "[400. 600.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKVrZ64dhBtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "3230a988-02e1-4d85-f14d-96247e533021"
      },
      "source": [
        "# 변수 노드 - 계속해서 업데이트 되는 변수\n",
        "W1 = tf.Variable(tf.random_normal([1])) #가우시안 분포의 임의의값 초기 변수로 사용\n",
        "b1 = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([1,2]))\n",
        "b2 = tf.Variable(tf.random_normal([1,2]))\n",
        "\n",
        "# 세션 생성\n",
        "sess = tf.Session()\n",
        "# <매우중요>변수노드 값 초기화, 변수 노드를 정의했다면 위해 반드시 실행\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(3):\n",
        "  W1 = W1 - step\n",
        "  b1 = b1 - step\n",
        "  W2 = W2 - step\n",
        "  b2 = b2 - step  \n",
        "\n",
        "  print('step = ', step, 'W1 = ',sess.run(W1),'b1 = ',sess.run(b1))\n",
        "  print('step = ', step, 'W2 = ',sess.run(W2),'b2 = ',sess.run(b2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 W1 =  [0.84073114] b1 =  [-1.056081]\n",
            "step =  0 W2 =  [[0.92338514 0.04250633]] b2 =  [[-0.82944494  0.4055577 ]]\n",
            "step =  1 W1 =  [-0.15926886] b1 =  [-2.056081]\n",
            "step =  1 W2 =  [[-0.07661486 -0.95749366]] b2 =  [[-1.8294449 -0.5944423]]\n",
            "step =  2 W1 =  [-2.1592689] b1 =  [-4.056081]\n",
            "step =  2 W2 =  [[-2.0766149 -2.9574938]] b2 =  [[-3.829445  -2.5944424]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLbw-PyLisIX",
        "colab_type": "text"
      },
      "source": [
        "# linear Reg 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Y64yVBkv2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR38kueSizNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "71ac7887-1b62-4bb0-84b9-78480cc54a0e"
      },
      "source": [
        "# 1. 데이터 분리\n",
        "loaded_data = np.loadtxt('/content/data-01.csv',delimiter=',')\n",
        "x_data = loaded_data[:,0:-1]\n",
        "t_data = loaded_data[:,[-1]]\n",
        "print(x_data.shape, t_data.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25, 3) (25, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXa4lCM6l2-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. 데이터 입력\n",
        "W = tf.Variable(tf.random_normal([3,1]))\n",
        "b = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None,3]) # None을 사용하면 몇개의 행이와도 열만 맞으면 사용 가능\n",
        "T = tf.placeholder(tf.float32, [None,1]) \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCQsjxlhmiWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. 선형 회귀\n",
        "# 4. 손실 함수\n",
        "y = tf.matmul(X,W) + b\n",
        "loss = tf.reduce_mean(tf.square(y-T)) # MSE 손실함수 정의 "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyStemHum1KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. W,b 최적화(경사하강법)\n",
        "learning_rate = 1e-5\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate) # 경사하강법 알고리즘 적용되는 optimizer\n",
        "# 최적화 알고리즘은 다수 존재\n",
        "train = optimizer.minimize(loss) #손실함수 최소화"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uai74P6SnjQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "d49429ac-71e6-41cb-8684-d747009d0b5c"
      },
      "source": [
        "with tf.Session() as sess: # with 사용하면 session.close 해주지 않아도 됨\n",
        "  sess.run(tf.global_variables_initializer()) # 변수 노드 tf.Variable 초기화\n",
        "  for step in range(8001):\n",
        "    loss_val, y_val, _ = sess.run([loss,y,train], feed_dict={X:x_data, T:t_data})\n",
        "    if step % 400 ==0:\n",
        "      print('stpe= ',step,'loss_val= ',loss_val)\n",
        "  print('\\nPrediction is', sess.run(y, feed_dict={X:[[100,98,81]]}))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stpe=  0 loss_val=  16202.138\n",
            "stpe=  400 loss_val=  60.859207\n",
            "stpe=  800 loss_val=  44.53538\n",
            "stpe=  1200 loss_val=  33.087692\n",
            "stpe=  1600 loss_val=  25.05846\n",
            "stpe=  2000 loss_val=  19.425756\n",
            "stpe=  2400 loss_val=  15.473666\n",
            "stpe=  2800 loss_val=  12.7001\n",
            "stpe=  3200 loss_val=  10.753091\n",
            "stpe=  3600 loss_val=  9.385851\n",
            "stpe=  4000 loss_val=  8.425397\n",
            "stpe=  4400 loss_val=  7.750395\n",
            "stpe=  4800 loss_val=  7.275797\n",
            "stpe=  5200 loss_val=  6.941881\n",
            "stpe=  5600 loss_val=  6.706813\n",
            "stpe=  6000 loss_val=  6.541179\n",
            "stpe=  6400 loss_val=  6.4243536\n",
            "stpe=  6800 loss_val=  6.341858\n",
            "stpe=  7200 loss_val=  6.2835364\n",
            "stpe=  7600 loss_val=  6.2422314\n",
            "stpe=  8000 loss_val=  6.2129297\n",
            "\n",
            "Prediction is [[179.33842]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82WH87zFpK2V",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Reg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtoCRRHJpQtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "953ba1d6-7c00-465a-ce41-5b4e25b73ba3"
      },
      "source": [
        "# 1. 데이터 분리\n",
        "loaded_data = np.loadtxt('/content/diabetes.csv',delimiter=',')\n",
        "x_data = loaded_data[:,0:-1]\n",
        "t_data = loaded_data[:,[-1]]\n",
        "print(x_data.shape, t_data.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(759, 8) (759, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kw_R6Cap4Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. 데이터 입력\n",
        "W = tf.Variable(tf.random_normal([8,1]))\n",
        "b = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None,8]) # None을 사용하면 몇개의 행이와도 열만 맞으면 사용 가능\n",
        "T = tf.placeholder(tf.float32, [None,1]) \n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlF47Fy-p89J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. 선형 회귀\n",
        "# 4. 손실 함수\n",
        "Z = tf.matmul(X,W) + b\n",
        "y = tf.sigmoid(Z)\n",
        "\n",
        "loss =  -tf.reduce_mean(T*tf.log(y) + (1-T)*tf.log(1-y))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEYyvvekrlv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate) # 오차 역전파를 이용해 W,b 최적화\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oPBCkpBrxlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = tf.cast(y>0.5,dtype=tf.float32) # sigmoid값이 0.5보다 크면 True\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,T), dtype=tf.float32))\n",
        "# equal -> predicted = y => True else False\n",
        "# cast -> True, False를 1,0 으로 변경\n",
        "# reduce_mean -> 평균계산"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ld9zh_sB0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "cd751018-b50a-4a93-fb74-6395497017e3"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer()) #변수 노드 초기화\n",
        "  for step in range(20001):\n",
        "    loss_val, _ = sess.run([loss,train],feed_dict={X:x_data,T:t_data})\n",
        "\n",
        "    if step % 500 ==0:\n",
        "      print('step = ',step, 'loss_val = ',loss_val)\n",
        "\n",
        "  y_val, predicted_val, accuracy_val = sess.run([y,predicted,accuracy], feed_dict={X:x_data, T:t_data})\n",
        "  print('\\ny_val.shape = ',y_val.shape,', predicted_val = ',predicted_val.shape)\n",
        "  print('\\nAccuracy = ',accuracy_val)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 loss_val =  0.7174718\n",
            "step =  500 loss_val =  0.66818476\n",
            "step =  1000 loss_val =  0.62913656\n",
            "step =  1500 loss_val =  0.59839255\n",
            "step =  2000 loss_val =  0.57432\n",
            "step =  2500 loss_val =  0.55548316\n",
            "step =  3000 loss_val =  0.54069406\n",
            "step =  3500 loss_val =  0.52901196\n",
            "step =  4000 loss_val =  0.51971394\n",
            "step =  4500 loss_val =  0.5122515\n",
            "step =  5000 loss_val =  0.50621164\n",
            "step =  5500 loss_val =  0.5012824\n",
            "step =  6000 loss_val =  0.4972275\n",
            "step =  6500 loss_val =  0.49386632\n",
            "step =  7000 loss_val =  0.49106023\n",
            "step =  7500 loss_val =  0.48870182\n",
            "step =  8000 loss_val =  0.48670688\n",
            "step =  8500 loss_val =  0.48500934\n",
            "step =  9000 loss_val =  0.48355678\n",
            "step =  9500 loss_val =  0.48230726\n",
            "step =  10000 loss_val =  0.4812269\n",
            "step =  10500 loss_val =  0.48028842\n",
            "step =  11000 loss_val =  0.47946963\n",
            "step =  11500 loss_val =  0.47875217\n",
            "step =  12000 loss_val =  0.47812104\n",
            "step =  12500 loss_val =  0.47756362\n",
            "step =  13000 loss_val =  0.4770696\n",
            "step =  13500 loss_val =  0.47663018\n",
            "step =  14000 loss_val =  0.4762381\n",
            "step =  14500 loss_val =  0.47588712\n",
            "step =  15000 loss_val =  0.47557208\n",
            "step =  15500 loss_val =  0.47528833\n",
            "step =  16000 loss_val =  0.4750321\n",
            "step =  16500 loss_val =  0.4748002\n",
            "step =  17000 loss_val =  0.47458968\n",
            "step =  17500 loss_val =  0.47439802\n",
            "step =  18000 loss_val =  0.47422323\n",
            "step =  18500 loss_val =  0.47406355\n",
            "step =  19000 loss_val =  0.4739172\n",
            "step =  19500 loss_val =  0.47378278\n",
            "step =  20000 loss_val =  0.4736591\n",
            "\n",
            "y_val.shape =  (759, 1) , predicted_val =  (759, 1)\n",
            "\n",
            "Accuracy =  0.7720685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhkDIkwdqqDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zSYD-uUrztl",
        "colab_type": "text"
      },
      "source": [
        "### 텐서플로우는 은닉층에서는 sigmoid 대신 relu 함수, 출력층에서는 sortmax 함수 사용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ralV1ustlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1je6yR8RtB7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "0ec5d32d-764c-47a6-bf5e-c127cceac4be"
      },
      "source": [
        "mnist = input_data.read_data_sets('MNIST_data/',one_hot=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-d08c12c637be>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ygfFdMgtQQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ca518d71-47fb-4278-c34b-42a428e82e06"
      },
      "source": [
        "print('\\n',mnist.train.num_examples,mnist.test.num_examples,mnist.validation.num_examples)\n",
        "print('train image shape',np.shape(mnist.train.images))\n",
        "print('train label shape',np.shape(mnist.train.labels))\n",
        "print(np.shape(mnist.test.images))\n",
        "print(np.shape(mnist.test.labels))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 55000 10000 5000\n",
            "train image shape (55000, 784)\n",
            "train label shape (55000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrdlEzActrrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 하이퍼파라미터는 컴퓨터 성능에 따라 변경 가능\n",
        "learning_rate = 0.1   # 학습율\n",
        "epochs = 100          # 반복횟수\n",
        "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수\n",
        "\n",
        "input_nodes = 784     # 입력노드 개수\n",
        "hidden_nodes = 100    # 은닉노드 개수\n",
        "output_nodes = 10     # 출력노드 개수"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pl8KqruuK_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None, input_nodes])\n",
        "T = tf.placeholder(tf.float32, [None, output_nodes]) #Target\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))\n",
        "b2 = tf.Variable(tf.random_normal([hidden_nodes]))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes]))\n",
        "b3 = tf.Variable(tf.random_normal([output_nodes]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stJoJqMOuwgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z2 = tf.matmul(X,W2) + b2\n",
        "A2 = tf.nn.relu(Z2)\n",
        "\n",
        "Z3 = logits = tf.matmul(A2,W3) + b3\n",
        "y = A3 = tf.nn.softmax(Z3)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02vlBkVQvDyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3,labels=T))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3BUVwRfvvoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_val = tf.equal(tf.argmax(A3,1),tf.argmax(T,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val,dtype=tf.float32))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E1EONBowd0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2927c3c-f050-4c3e-9ef5-82ce416625a6"
      },
      "source": [
        "\n",
        "with  tf.Session()  as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
        "    \n",
        "    for i in range(epochs):    # 100 번 반복수행\n",
        "        \n",
        "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
        "\n",
        "        for step in range(total_batch):\n",
        "            \n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
        "        \n",
        "            if step % 100 == 0:\n",
        "                print(\"step = \", step, \", loss_val = \", loss_val)             \n",
        "    \n",
        "    # Accuracy 확인\n",
        "    test_x_data = mnist.test.images    # 10000 X 784\n",
        "    test_t_data = mnist.test.labels    # 10000 X 10\n",
        "    \n",
        "    accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n",
        "    \n",
        "    print(\"\\nAccuracy = \", accuracy_val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 , loss_val =  103.23072\n",
            "step =  100 , loss_val =  3.9515078\n",
            "step =  200 , loss_val =  3.293043\n",
            "step =  300 , loss_val =  1.3089633\n",
            "step =  400 , loss_val =  1.6956375\n",
            "step =  500 , loss_val =  1.5029268\n",
            "step =  0 , loss_val =  2.1039681\n",
            "step =  100 , loss_val =  1.1662147\n",
            "step =  200 , loss_val =  0.6804744\n",
            "step =  300 , loss_val =  0.69596696\n",
            "step =  400 , loss_val =  0.56577\n",
            "step =  500 , loss_val =  0.81567377\n",
            "step =  0 , loss_val =  0.80993456\n",
            "step =  100 , loss_val =  0.40694743\n",
            "step =  200 , loss_val =  1.1690364\n",
            "step =  300 , loss_val =  0.63719755\n",
            "step =  400 , loss_val =  0.98029715\n",
            "step =  500 , loss_val =  0.56272936\n",
            "step =  0 , loss_val =  0.31872058\n",
            "step =  100 , loss_val =  0.52275705\n",
            "step =  200 , loss_val =  0.31038764\n",
            "step =  300 , loss_val =  0.20409761\n",
            "step =  400 , loss_val =  0.43583575\n",
            "step =  500 , loss_val =  0.43886262\n",
            "step =  0 , loss_val =  0.5324902\n",
            "step =  100 , loss_val =  0.68017626\n",
            "step =  200 , loss_val =  0.5487034\n",
            "step =  300 , loss_val =  0.44120774\n",
            "step =  400 , loss_val =  0.80452365\n",
            "step =  500 , loss_val =  0.6004908\n",
            "step =  0 , loss_val =  0.2570124\n",
            "step =  100 , loss_val =  0.36919892\n",
            "step =  200 , loss_val =  0.468874\n",
            "step =  300 , loss_val =  0.3993924\n",
            "step =  400 , loss_val =  0.41624796\n",
            "step =  500 , loss_val =  0.65552676\n",
            "step =  0 , loss_val =  0.2206927\n",
            "step =  100 , loss_val =  0.24877502\n",
            "step =  200 , loss_val =  0.19639297\n",
            "step =  300 , loss_val =  0.34035805\n",
            "step =  400 , loss_val =  0.36242023\n",
            "step =  500 , loss_val =  0.53018713\n",
            "step =  0 , loss_val =  0.44201782\n",
            "step =  100 , loss_val =  0.23155934\n",
            "step =  200 , loss_val =  0.21883722\n",
            "step =  300 , loss_val =  0.32377857\n",
            "step =  400 , loss_val =  0.3059184\n",
            "step =  500 , loss_val =  0.31624597\n",
            "step =  0 , loss_val =  0.38561797\n",
            "step =  100 , loss_val =  0.4938225\n",
            "step =  200 , loss_val =  0.35737893\n",
            "step =  300 , loss_val =  0.26734227\n",
            "step =  400 , loss_val =  0.18654065\n",
            "step =  500 , loss_val =  0.5537859\n",
            "step =  0 , loss_val =  0.31697342\n",
            "step =  100 , loss_val =  0.3766386\n",
            "step =  200 , loss_val =  0.5317574\n",
            "step =  300 , loss_val =  0.2528118\n",
            "step =  400 , loss_val =  0.35057476\n",
            "step =  500 , loss_val =  0.22788005\n",
            "step =  0 , loss_val =  0.25787964\n",
            "step =  100 , loss_val =  0.1122546\n",
            "step =  200 , loss_val =  0.10254928\n",
            "step =  300 , loss_val =  0.35548195\n",
            "step =  400 , loss_val =  0.2775547\n",
            "step =  500 , loss_val =  0.332759\n",
            "step =  0 , loss_val =  0.40027985\n",
            "step =  100 , loss_val =  0.15235923\n",
            "step =  200 , loss_val =  0.2917096\n",
            "step =  300 , loss_val =  0.33430347\n",
            "step =  400 , loss_val =  0.396733\n",
            "step =  500 , loss_val =  0.23242834\n",
            "step =  0 , loss_val =  0.17680721\n",
            "step =  100 , loss_val =  0.3278311\n",
            "step =  200 , loss_val =  0.25647706\n",
            "step =  300 , loss_val =  0.2153045\n",
            "step =  400 , loss_val =  0.48727998\n",
            "step =  500 , loss_val =  0.14993462\n",
            "step =  0 , loss_val =  0.24686171\n",
            "step =  100 , loss_val =  0.4117968\n",
            "step =  200 , loss_val =  0.15344661\n",
            "step =  300 , loss_val =  0.22368933\n",
            "step =  400 , loss_val =  0.2723406\n",
            "step =  500 , loss_val =  0.15390527\n",
            "step =  0 , loss_val =  0.23944786\n",
            "step =  100 , loss_val =  0.16901079\n",
            "step =  200 , loss_val =  0.30831382\n",
            "step =  300 , loss_val =  0.45178968\n",
            "step =  400 , loss_val =  0.2468564\n",
            "step =  500 , loss_val =  0.13164662\n",
            "step =  0 , loss_val =  0.47291815\n",
            "step =  100 , loss_val =  0.21974748\n",
            "step =  200 , loss_val =  0.29488587\n",
            "step =  300 , loss_val =  0.22429642\n",
            "step =  400 , loss_val =  0.09458756\n",
            "step =  500 , loss_val =  0.16900901\n",
            "step =  0 , loss_val =  0.039258707\n",
            "step =  100 , loss_val =  0.17724557\n",
            "step =  200 , loss_val =  0.27894795\n",
            "step =  300 , loss_val =  0.34265122\n",
            "step =  400 , loss_val =  0.1683732\n",
            "step =  500 , loss_val =  0.2857633\n",
            "step =  0 , loss_val =  0.19241992\n",
            "step =  100 , loss_val =  0.3132351\n",
            "step =  200 , loss_val =  0.18801071\n",
            "step =  300 , loss_val =  0.1067726\n",
            "step =  400 , loss_val =  0.11548949\n",
            "step =  500 , loss_val =  0.13788089\n",
            "step =  0 , loss_val =  0.24061196\n",
            "step =  100 , loss_val =  0.49455592\n",
            "step =  200 , loss_val =  0.4597359\n",
            "step =  300 , loss_val =  0.11885777\n",
            "step =  400 , loss_val =  0.44288886\n",
            "step =  500 , loss_val =  0.122284524\n",
            "step =  0 , loss_val =  0.09101818\n",
            "step =  100 , loss_val =  0.20675883\n",
            "step =  200 , loss_val =  0.2949343\n",
            "step =  300 , loss_val =  0.17820945\n",
            "step =  400 , loss_val =  0.155071\n",
            "step =  500 , loss_val =  0.28881034\n",
            "step =  0 , loss_val =  0.32753262\n",
            "step =  100 , loss_val =  0.3271552\n",
            "step =  200 , loss_val =  0.20405082\n",
            "step =  300 , loss_val =  0.19957793\n",
            "step =  400 , loss_val =  0.20840646\n",
            "step =  500 , loss_val =  0.21878964\n",
            "step =  0 , loss_val =  0.14797445\n",
            "step =  100 , loss_val =  0.13647656\n",
            "step =  200 , loss_val =  0.22842759\n",
            "step =  300 , loss_val =  0.21100938\n",
            "step =  400 , loss_val =  0.24087512\n",
            "step =  500 , loss_val =  0.24157852\n",
            "step =  0 , loss_val =  0.048063222\n",
            "step =  100 , loss_val =  0.2980488\n",
            "step =  200 , loss_val =  0.370607\n",
            "step =  300 , loss_val =  0.14198697\n",
            "step =  400 , loss_val =  0.17002478\n",
            "step =  500 , loss_val =  0.09316581\n",
            "step =  0 , loss_val =  0.27311382\n",
            "step =  100 , loss_val =  0.11926524\n",
            "step =  200 , loss_val =  0.13064441\n",
            "step =  300 , loss_val =  0.27025577\n",
            "step =  400 , loss_val =  0.12093724\n",
            "step =  500 , loss_val =  0.25927737\n",
            "step =  0 , loss_val =  0.2780112\n",
            "step =  100 , loss_val =  0.20305704\n",
            "step =  200 , loss_val =  0.17876849\n",
            "step =  300 , loss_val =  0.12356129\n",
            "step =  400 , loss_val =  0.16018437\n",
            "step =  500 , loss_val =  0.18668602\n",
            "step =  0 , loss_val =  0.25155133\n",
            "step =  100 , loss_val =  0.15848508\n",
            "step =  200 , loss_val =  0.30715233\n",
            "step =  300 , loss_val =  0.13690023\n",
            "step =  400 , loss_val =  0.18069479\n",
            "step =  500 , loss_val =  0.4452552\n",
            "step =  0 , loss_val =  0.09756121\n",
            "step =  100 , loss_val =  0.32959834\n",
            "step =  200 , loss_val =  0.13813546\n",
            "step =  300 , loss_val =  0.13521726\n",
            "step =  400 , loss_val =  0.10624732\n",
            "step =  500 , loss_val =  0.12819032\n",
            "step =  0 , loss_val =  0.09178073\n",
            "step =  100 , loss_val =  0.16885737\n",
            "step =  200 , loss_val =  0.21947648\n",
            "step =  300 , loss_val =  0.1841172\n",
            "step =  400 , loss_val =  0.32885316\n",
            "step =  500 , loss_val =  0.18526712\n",
            "step =  0 , loss_val =  0.15011646\n",
            "step =  100 , loss_val =  0.19106525\n",
            "step =  200 , loss_val =  0.13546418\n",
            "step =  300 , loss_val =  0.1392202\n",
            "step =  400 , loss_val =  0.08861977\n",
            "step =  500 , loss_val =  0.0854078\n",
            "step =  0 , loss_val =  0.20691055\n",
            "step =  100 , loss_val =  0.36133382\n",
            "step =  200 , loss_val =  0.22347575\n",
            "step =  300 , loss_val =  0.076618254\n",
            "step =  400 , loss_val =  0.19469452\n",
            "step =  500 , loss_val =  0.34184396\n",
            "step =  0 , loss_val =  0.12179463\n",
            "step =  100 , loss_val =  0.19451211\n",
            "step =  200 , loss_val =  0.16253963\n",
            "step =  300 , loss_val =  0.12141885\n",
            "step =  400 , loss_val =  0.08074667\n",
            "step =  500 , loss_val =  0.1828689\n",
            "step =  0 , loss_val =  0.17582336\n",
            "step =  100 , loss_val =  0.12853318\n",
            "step =  200 , loss_val =  0.1268227\n",
            "step =  300 , loss_val =  0.16896679\n",
            "step =  400 , loss_val =  0.1230277\n",
            "step =  500 , loss_val =  0.17941612\n",
            "step =  0 , loss_val =  0.20893177\n",
            "step =  100 , loss_val =  0.2310576\n",
            "step =  200 , loss_val =  0.17616625\n",
            "step =  300 , loss_val =  0.17953661\n",
            "step =  400 , loss_val =  0.09839628\n",
            "step =  500 , loss_val =  0.1169638\n",
            "step =  0 , loss_val =  0.19705062\n",
            "step =  100 , loss_val =  0.1681249\n",
            "step =  200 , loss_val =  0.08436506\n",
            "step =  300 , loss_val =  0.20257826\n",
            "step =  400 , loss_val =  0.0765554\n",
            "step =  500 , loss_val =  0.07002344\n",
            "step =  0 , loss_val =  0.19645175\n",
            "step =  100 , loss_val =  0.10149214\n",
            "step =  200 , loss_val =  0.12187147\n",
            "step =  300 , loss_val =  0.18467148\n",
            "step =  400 , loss_val =  0.06915389\n",
            "step =  500 , loss_val =  0.20680742\n",
            "step =  0 , loss_val =  0.07779236\n",
            "step =  100 , loss_val =  0.21475205\n",
            "step =  200 , loss_val =  0.12778158\n",
            "step =  300 , loss_val =  0.058815937\n",
            "step =  400 , loss_val =  0.119654186\n",
            "step =  500 , loss_val =  0.19935893\n",
            "step =  0 , loss_val =  0.1806651\n",
            "step =  100 , loss_val =  0.10322782\n",
            "step =  200 , loss_val =  0.16646905\n",
            "step =  300 , loss_val =  0.29600713\n",
            "step =  400 , loss_val =  0.32433704\n",
            "step =  500 , loss_val =  0.12541425\n",
            "step =  0 , loss_val =  0.14007668\n",
            "step =  100 , loss_val =  0.115730874\n",
            "step =  200 , loss_val =  0.20934048\n",
            "step =  300 , loss_val =  0.10759862\n",
            "step =  400 , loss_val =  0.21744901\n",
            "step =  500 , loss_val =  0.313323\n",
            "step =  0 , loss_val =  0.12617208\n",
            "step =  100 , loss_val =  0.36558038\n",
            "step =  200 , loss_val =  0.14694032\n",
            "step =  300 , loss_val =  0.14426956\n",
            "step =  400 , loss_val =  0.18076949\n",
            "step =  500 , loss_val =  0.13802548\n",
            "step =  0 , loss_val =  0.18676879\n",
            "step =  100 , loss_val =  0.11959085\n",
            "step =  200 , loss_val =  0.19752981\n",
            "step =  300 , loss_val =  0.14389502\n",
            "step =  400 , loss_val =  0.057007838\n",
            "step =  500 , loss_val =  0.15055072\n",
            "step =  0 , loss_val =  0.22094762\n",
            "step =  100 , loss_val =  0.1157154\n",
            "step =  200 , loss_val =  0.3398153\n",
            "step =  300 , loss_val =  0.14184389\n",
            "step =  400 , loss_val =  0.08122723\n",
            "step =  500 , loss_val =  0.33049378\n",
            "step =  0 , loss_val =  0.09385518\n",
            "step =  100 , loss_val =  0.22623661\n",
            "step =  200 , loss_val =  0.29588944\n",
            "step =  300 , loss_val =  0.16419104\n",
            "step =  400 , loss_val =  0.1181672\n",
            "step =  500 , loss_val =  0.12297555\n",
            "step =  0 , loss_val =  0.15354533\n",
            "step =  100 , loss_val =  0.08734811\n",
            "step =  200 , loss_val =  0.23790531\n",
            "step =  300 , loss_val =  0.31067023\n",
            "step =  400 , loss_val =  0.07679453\n",
            "step =  500 , loss_val =  0.04867281\n",
            "step =  0 , loss_val =  0.0437391\n",
            "step =  100 , loss_val =  0.029407121\n",
            "step =  200 , loss_val =  0.16474704\n",
            "step =  300 , loss_val =  0.05617974\n",
            "step =  400 , loss_val =  0.14681521\n",
            "step =  500 , loss_val =  0.083614916\n",
            "step =  0 , loss_val =  0.03577216\n",
            "step =  100 , loss_val =  0.16187277\n",
            "step =  200 , loss_val =  0.16847381\n",
            "step =  300 , loss_val =  0.10458579\n",
            "step =  400 , loss_val =  0.21095692\n",
            "step =  500 , loss_val =  0.113573916\n",
            "step =  0 , loss_val =  0.07484294\n",
            "step =  100 , loss_val =  0.07434548\n",
            "step =  200 , loss_val =  0.38150898\n",
            "step =  300 , loss_val =  0.10738529\n",
            "step =  400 , loss_val =  0.19251876\n",
            "step =  500 , loss_val =  0.13599296\n",
            "step =  0 , loss_val =  0.1815787\n",
            "step =  100 , loss_val =  0.17244919\n",
            "step =  200 , loss_val =  0.06644435\n",
            "step =  300 , loss_val =  0.06810676\n",
            "step =  400 , loss_val =  0.09931504\n",
            "step =  500 , loss_val =  0.22616266\n",
            "step =  0 , loss_val =  0.08884451\n",
            "step =  100 , loss_val =  0.09380791\n",
            "step =  200 , loss_val =  0.12773775\n",
            "step =  300 , loss_val =  0.12864645\n",
            "step =  400 , loss_val =  0.071726084\n",
            "step =  500 , loss_val =  0.10382362\n",
            "step =  0 , loss_val =  0.07243992\n",
            "step =  100 , loss_val =  0.18723734\n",
            "step =  200 , loss_val =  0.08377542\n",
            "step =  300 , loss_val =  0.20141785\n",
            "step =  400 , loss_val =  0.098948896\n",
            "step =  500 , loss_val =  0.07776276\n",
            "step =  0 , loss_val =  0.11342014\n",
            "step =  100 , loss_val =  0.03820719\n",
            "step =  200 , loss_val =  0.15260398\n",
            "step =  300 , loss_val =  0.12652479\n",
            "step =  400 , loss_val =  0.14888377\n",
            "step =  500 , loss_val =  0.15125875\n",
            "step =  0 , loss_val =  0.07610049\n",
            "step =  100 , loss_val =  0.07614739\n",
            "step =  200 , loss_val =  0.09709277\n",
            "step =  300 , loss_val =  0.15597293\n",
            "step =  400 , loss_val =  0.14937657\n",
            "step =  500 , loss_val =  0.120465524\n",
            "step =  0 , loss_val =  0.12893325\n",
            "step =  100 , loss_val =  0.055471458\n",
            "step =  200 , loss_val =  0.097260684\n",
            "step =  300 , loss_val =  0.10896734\n",
            "step =  400 , loss_val =  0.05096512\n",
            "step =  500 , loss_val =  0.05097888\n",
            "step =  0 , loss_val =  0.07894816\n",
            "step =  100 , loss_val =  0.22310677\n",
            "step =  200 , loss_val =  0.1396315\n",
            "step =  300 , loss_val =  0.14646807\n",
            "step =  400 , loss_val =  0.21050093\n",
            "step =  500 , loss_val =  0.048521053\n",
            "step =  0 , loss_val =  0.15427533\n",
            "step =  100 , loss_val =  0.2844966\n",
            "step =  200 , loss_val =  0.3738366\n",
            "step =  300 , loss_val =  0.16273323\n",
            "step =  400 , loss_val =  0.039699633\n",
            "step =  500 , loss_val =  0.19898212\n",
            "step =  0 , loss_val =  0.16862829\n",
            "step =  100 , loss_val =  0.17052771\n",
            "step =  200 , loss_val =  0.13264675\n",
            "step =  300 , loss_val =  0.15205252\n",
            "step =  400 , loss_val =  0.09552789\n",
            "step =  500 , loss_val =  0.03570088\n",
            "step =  0 , loss_val =  0.12130702\n",
            "step =  100 , loss_val =  0.06121669\n",
            "step =  200 , loss_val =  0.14038469\n",
            "step =  300 , loss_val =  0.12659721\n",
            "step =  400 , loss_val =  0.26364002\n",
            "step =  500 , loss_val =  0.062023077\n",
            "step =  0 , loss_val =  0.051793195\n",
            "step =  100 , loss_val =  0.1481751\n",
            "step =  200 , loss_val =  0.19894864\n",
            "step =  300 , loss_val =  0.1304335\n",
            "step =  400 , loss_val =  0.0421122\n",
            "step =  500 , loss_val =  0.10268207\n",
            "step =  0 , loss_val =  0.054716367\n",
            "step =  100 , loss_val =  0.1386896\n",
            "step =  200 , loss_val =  0.055807\n",
            "step =  300 , loss_val =  0.18155986\n",
            "step =  400 , loss_val =  0.021354116\n",
            "step =  500 , loss_val =  0.0917475\n",
            "step =  0 , loss_val =  0.12926508\n",
            "step =  100 , loss_val =  0.06835263\n",
            "step =  200 , loss_val =  0.27766526\n",
            "step =  300 , loss_val =  0.09295141\n",
            "step =  400 , loss_val =  0.23199856\n",
            "step =  500 , loss_val =  0.32809624\n",
            "step =  0 , loss_val =  0.16577236\n",
            "step =  100 , loss_val =  0.18626603\n",
            "step =  200 , loss_val =  0.21924189\n",
            "step =  300 , loss_val =  0.065107554\n",
            "step =  400 , loss_val =  0.07221851\n",
            "step =  500 , loss_val =  0.015529418\n",
            "step =  0 , loss_val =  0.16822392\n",
            "step =  100 , loss_val =  0.070466585\n",
            "step =  200 , loss_val =  0.26639152\n",
            "step =  300 , loss_val =  0.06523053\n",
            "step =  400 , loss_val =  0.04529311\n",
            "step =  500 , loss_val =  0.20351262\n",
            "step =  0 , loss_val =  0.053613845\n",
            "step =  100 , loss_val =  0.09364817\n",
            "step =  200 , loss_val =  0.09995749\n",
            "step =  300 , loss_val =  0.19247997\n",
            "step =  400 , loss_val =  0.11515112\n",
            "step =  500 , loss_val =  0.11478486\n",
            "step =  0 , loss_val =  0.14916395\n",
            "step =  100 , loss_val =  0.06430155\n",
            "step =  200 , loss_val =  0.08699649\n",
            "step =  300 , loss_val =  0.11217816\n",
            "step =  400 , loss_val =  0.13344884\n",
            "step =  500 , loss_val =  0.05142428\n",
            "step =  0 , loss_val =  0.023547301\n",
            "step =  100 , loss_val =  0.19877106\n",
            "step =  200 , loss_val =  0.09483133\n",
            "step =  300 , loss_val =  0.04782745\n",
            "step =  400 , loss_val =  0.18499485\n",
            "step =  500 , loss_val =  0.10567026\n",
            "step =  0 , loss_val =  0.0366477\n",
            "step =  100 , loss_val =  0.2678957\n",
            "step =  200 , loss_val =  0.19881825\n",
            "step =  300 , loss_val =  0.105158396\n",
            "step =  400 , loss_val =  0.14226629\n",
            "step =  500 , loss_val =  0.09430649\n",
            "step =  0 , loss_val =  0.051138483\n",
            "step =  100 , loss_val =  0.118292324\n",
            "step =  200 , loss_val =  0.105320126\n",
            "step =  300 , loss_val =  0.085147984\n",
            "step =  400 , loss_val =  0.12400964\n",
            "step =  500 , loss_val =  0.18903928\n",
            "step =  0 , loss_val =  0.11090647\n",
            "step =  100 , loss_val =  0.0942785\n",
            "step =  200 , loss_val =  0.10185705\n",
            "step =  300 , loss_val =  0.12323031\n",
            "step =  400 , loss_val =  0.26002342\n",
            "step =  500 , loss_val =  0.17942297\n",
            "step =  0 , loss_val =  0.26119202\n",
            "step =  100 , loss_val =  0.18170998\n",
            "step =  200 , loss_val =  0.06366773\n",
            "step =  300 , loss_val =  0.10922472\n",
            "step =  400 , loss_val =  0.10947032\n",
            "step =  500 , loss_val =  0.06491255\n",
            "step =  0 , loss_val =  0.16728315\n",
            "step =  100 , loss_val =  0.14158511\n",
            "step =  200 , loss_val =  0.19115266\n",
            "step =  300 , loss_val =  0.06556278\n",
            "step =  400 , loss_val =  0.04662781\n",
            "step =  500 , loss_val =  0.08761675\n",
            "step =  0 , loss_val =  0.13428578\n",
            "step =  100 , loss_val =  0.07171027\n",
            "step =  200 , loss_val =  0.13176359\n",
            "step =  300 , loss_val =  0.09086639\n",
            "step =  400 , loss_val =  0.08077607\n",
            "step =  500 , loss_val =  0.10860798\n",
            "step =  0 , loss_val =  0.105226375\n",
            "step =  100 , loss_val =  0.122594975\n",
            "step =  200 , loss_val =  0.09524672\n",
            "step =  300 , loss_val =  0.07074929\n",
            "step =  400 , loss_val =  0.065756075\n",
            "step =  500 , loss_val =  0.04172748\n",
            "step =  0 , loss_val =  0.07093745\n",
            "step =  100 , loss_val =  0.08339085\n",
            "step =  200 , loss_val =  0.12292841\n",
            "step =  300 , loss_val =  0.055219196\n",
            "step =  400 , loss_val =  0.13588816\n",
            "step =  500 , loss_val =  0.0638906\n",
            "step =  0 , loss_val =  0.06622046\n",
            "step =  100 , loss_val =  0.05519066\n",
            "step =  200 , loss_val =  0.11106339\n",
            "step =  300 , loss_val =  0.05532271\n",
            "step =  400 , loss_val =  0.07022915\n",
            "step =  500 , loss_val =  0.027764233\n",
            "step =  0 , loss_val =  0.092562005\n",
            "step =  100 , loss_val =  0.057740074\n",
            "step =  200 , loss_val =  0.05576602\n",
            "step =  300 , loss_val =  0.16026379\n",
            "step =  400 , loss_val =  0.1718317\n",
            "step =  500 , loss_val =  0.063823864\n",
            "step =  0 , loss_val =  0.1041814\n",
            "step =  100 , loss_val =  0.030949943\n",
            "step =  200 , loss_val =  0.05368763\n",
            "step =  300 , loss_val =  0.1156767\n",
            "step =  400 , loss_val =  0.22028589\n",
            "step =  500 , loss_val =  0.08522578\n",
            "step =  0 , loss_val =  0.09555445\n",
            "step =  100 , loss_val =  0.15414251\n",
            "step =  200 , loss_val =  0.086835906\n",
            "step =  300 , loss_val =  0.15206593\n",
            "step =  400 , loss_val =  0.22049393\n",
            "step =  500 , loss_val =  0.14769632\n",
            "step =  0 , loss_val =  0.060537692\n",
            "step =  100 , loss_val =  0.0726482\n",
            "step =  200 , loss_val =  0.01820387\n",
            "step =  300 , loss_val =  0.11529751\n",
            "step =  400 , loss_val =  0.031200487\n",
            "step =  500 , loss_val =  0.050852105\n",
            "step =  0 , loss_val =  0.0785874\n",
            "step =  100 , loss_val =  0.086611405\n",
            "step =  200 , loss_val =  0.21043092\n",
            "step =  300 , loss_val =  0.0884525\n",
            "step =  400 , loss_val =  0.04889299\n",
            "step =  500 , loss_val =  0.078631856\n",
            "step =  0 , loss_val =  0.08066645\n",
            "step =  100 , loss_val =  0.07436665\n",
            "step =  200 , loss_val =  0.02678524\n",
            "step =  300 , loss_val =  0.158156\n",
            "step =  400 , loss_val =  0.09008041\n",
            "step =  500 , loss_val =  0.062377706\n",
            "step =  0 , loss_val =  0.03825843\n",
            "step =  100 , loss_val =  0.1591682\n",
            "step =  200 , loss_val =  0.14197624\n",
            "step =  300 , loss_val =  0.037340447\n",
            "step =  400 , loss_val =  0.09788708\n",
            "step =  500 , loss_val =  0.087137625\n",
            "step =  0 , loss_val =  0.24137226\n",
            "step =  100 , loss_val =  0.084456585\n",
            "step =  200 , loss_val =  0.1911405\n",
            "step =  300 , loss_val =  0.16544518\n",
            "step =  400 , loss_val =  0.14501624\n",
            "step =  500 , loss_val =  0.16318561\n",
            "step =  0 , loss_val =  0.092238314\n",
            "step =  100 , loss_val =  0.10549946\n",
            "step =  200 , loss_val =  0.05586133\n",
            "step =  300 , loss_val =  0.28732187\n",
            "step =  400 , loss_val =  0.09745507\n",
            "step =  500 , loss_val =  0.13151902\n",
            "step =  0 , loss_val =  0.090730675\n",
            "step =  100 , loss_val =  0.11986495\n",
            "step =  200 , loss_val =  0.11773907\n",
            "step =  300 , loss_val =  0.19141701\n",
            "step =  400 , loss_val =  0.07107674\n",
            "step =  500 , loss_val =  0.09128179\n",
            "step =  0 , loss_val =  0.055026118\n",
            "step =  100 , loss_val =  0.18034296\n",
            "step =  200 , loss_val =  0.08420559\n",
            "step =  300 , loss_val =  0.11320996\n",
            "step =  400 , loss_val =  0.123120934\n",
            "step =  500 , loss_val =  0.023147203\n",
            "step =  0 , loss_val =  0.095849544\n",
            "step =  100 , loss_val =  0.03656088\n",
            "step =  200 , loss_val =  0.10146324\n",
            "step =  300 , loss_val =  0.12831575\n",
            "step =  400 , loss_val =  0.177843\n",
            "step =  500 , loss_val =  0.043869153\n",
            "step =  0 , loss_val =  0.07027289\n",
            "step =  100 , loss_val =  0.06410596\n",
            "step =  200 , loss_val =  0.060179792\n",
            "step =  300 , loss_val =  0.07275157\n",
            "step =  400 , loss_val =  0.1626166\n",
            "step =  500 , loss_val =  0.07068342\n",
            "step =  0 , loss_val =  0.05578674\n",
            "step =  100 , loss_val =  0.11583933\n",
            "step =  200 , loss_val =  0.09885276\n",
            "step =  300 , loss_val =  0.107189074\n",
            "step =  400 , loss_val =  0.07450444\n",
            "step =  500 , loss_val =  0.18596202\n",
            "step =  0 , loss_val =  0.076703005\n",
            "step =  100 , loss_val =  0.10466807\n",
            "step =  200 , loss_val =  0.07733611\n",
            "step =  300 , loss_val =  0.062489577\n",
            "step =  400 , loss_val =  0.12749942\n",
            "step =  500 , loss_val =  0.03182931\n",
            "step =  0 , loss_val =  0.04600082\n",
            "step =  100 , loss_val =  0.023855167\n",
            "step =  200 , loss_val =  0.0900972\n",
            "step =  300 , loss_val =  0.16209888\n",
            "step =  400 , loss_val =  0.10613469\n",
            "step =  500 , loss_val =  0.102257684\n",
            "step =  0 , loss_val =  0.06193129\n",
            "step =  100 , loss_val =  0.08507871\n",
            "step =  200 , loss_val =  0.13671045\n",
            "step =  300 , loss_val =  0.10536739\n",
            "step =  400 , loss_val =  0.055470146\n",
            "step =  500 , loss_val =  0.0795461\n",
            "step =  0 , loss_val =  0.075253464\n",
            "step =  100 , loss_val =  0.07472893\n",
            "step =  200 , loss_val =  0.08795796\n",
            "step =  300 , loss_val =  0.063032255\n",
            "step =  400 , loss_val =  0.29908353\n",
            "step =  500 , loss_val =  0.10327572\n",
            "step =  0 , loss_val =  0.03670775\n",
            "step =  100 , loss_val =  0.15236482\n",
            "step =  200 , loss_val =  0.052717347\n",
            "step =  300 , loss_val =  0.08882699\n",
            "step =  400 , loss_val =  0.0200045\n",
            "step =  500 , loss_val =  0.061702836\n",
            "step =  0 , loss_val =  0.046465073\n",
            "step =  100 , loss_val =  0.030101368\n",
            "step =  200 , loss_val =  0.08748743\n",
            "step =  300 , loss_val =  0.14359672\n",
            "step =  400 , loss_val =  0.08317401\n",
            "step =  500 , loss_val =  0.10329781\n",
            "step =  0 , loss_val =  0.054825276\n",
            "step =  100 , loss_val =  0.21382508\n",
            "step =  200 , loss_val =  0.06941102\n",
            "step =  300 , loss_val =  0.059464622\n",
            "step =  400 , loss_val =  0.08578485\n",
            "step =  500 , loss_val =  0.13537292\n",
            "step =  0 , loss_val =  0.063593976\n",
            "step =  100 , loss_val =  0.06333521\n",
            "step =  200 , loss_val =  0.050809685\n",
            "step =  300 , loss_val =  0.12471956\n",
            "step =  400 , loss_val =  0.12102563\n",
            "step =  500 , loss_val =  0.03881249\n",
            "step =  0 , loss_val =  0.14952566\n",
            "step =  100 , loss_val =  0.031767245\n",
            "step =  200 , loss_val =  0.116426095\n",
            "step =  300 , loss_val =  0.093069404\n",
            "step =  400 , loss_val =  0.031803757\n",
            "step =  500 , loss_val =  0.12107397\n",
            "step =  0 , loss_val =  0.08196998\n",
            "step =  100 , loss_val =  0.1884351\n",
            "step =  200 , loss_val =  0.039618857\n",
            "step =  300 , loss_val =  0.11499145\n",
            "step =  400 , loss_val =  0.09352779\n",
            "step =  500 , loss_val =  0.06976331\n",
            "step =  0 , loss_val =  0.0996014\n",
            "step =  100 , loss_val =  0.11567286\n",
            "step =  200 , loss_val =  0.03717208\n",
            "step =  300 , loss_val =  0.08517899\n",
            "step =  400 , loss_val =  0.034559757\n",
            "step =  500 , loss_val =  0.109214\n",
            "step =  0 , loss_val =  0.06310294\n",
            "step =  100 , loss_val =  0.059657488\n",
            "step =  200 , loss_val =  0.046021882\n",
            "step =  300 , loss_val =  0.10007548\n",
            "step =  400 , loss_val =  0.08753849\n",
            "step =  500 , loss_val =  0.048712883\n",
            "step =  0 , loss_val =  0.07264383\n",
            "step =  100 , loss_val =  0.06570747\n",
            "step =  200 , loss_val =  0.026315674\n",
            "step =  300 , loss_val =  0.07785745\n",
            "step =  400 , loss_val =  0.07769821\n",
            "step =  500 , loss_val =  0.117243014\n",
            "\n",
            "Accuracy =  0.9527\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}